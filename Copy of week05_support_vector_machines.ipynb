{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Copy of week05_support_vector_machines.ipynb","provenance":[{"file_id":"1wFdAIA2AKl5FKuM7q1oSWjLQLyUA4fST","timestamp":1585903012494}]}},"cells":[{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"8d28e700952e0068338ecbc5b8078385","grade":false,"grade_id":"cell-23ebfe623390adc7","locked":true,"schema_version":3,"solution":false,"task":false},"id":"koSm7lhtLh0o","colab_type":"text"},"source":["# Overview  <a name='objectives' />\n","\n","This notebook introduces you to Support Vector Machines. \n","\n","The topics that will be covered are:\n","\n","1. <a href=#svm_problem>The SVM Problem</a>\n","2. <a href=#kernels>Kernels</a>\n","3. <a href=#nu_svm>$\\nu$-SVM (Advanced)</a>\n","4. <a href=#multiclass_svm>Multiclass SVM (Advanced)</a>\n","5. <a href=#sklearn>Sckit-Learn Implementation</a>\n","\n","### Programming Tasks\n","For the programming tasks you will need to replace the following comment and exception with your own code:\n","\n","```python\n","# YOUR CODE HERE\n","raise NotImplementedError()\n","```\n","\n","Most programming tasks are followed by a cell with tests (using the `assert` function from python). You can use these cells while developing your implementation and for validating your implementation.\n","\n","### Open Questions\n","The notebook also contains a few open questions. For the open questions you can put your answer in the cell below the question, replace the text \"YOUR ANSWER HERE\" with your own answer."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c1e5e61d67ae7b15c4ec56d6a9196921","grade":false,"grade_id":"cell-c4c8a039b40d78b9","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ya6V8wJLLh0r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"5cef5718-339c-4c50-98b0-f77038299570","executionInfo":{"status":"ok","timestamp":1585903482091,"user_tz":-120,"elapsed":5657,"user":{"displayName":"David Kurz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe_wM_K4xbhRICUKcX-SppDNFL1Q7WyvevxsgB=s64","userId":"17311286808322757220"}}},"source":["# Make sure that the required libraries are installed\n","# If you are using Google Colab, remember to upload the requirements file before \n","# running this cell\n","# If you are running this notebook locally, the requirements file needs to be in \n","# the same location as this notebook\n","import sys\n","!{sys.executable} -m pip install -r requirements_week05.txt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements_week05.txt'\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"3b3a539a259fe3292d57bdd00b7a1b1f","grade":false,"grade_id":"cell-cbe97c95cc051344","locked":true,"schema_version":3,"solution":false,"task":false},"id":"bjDKNabrLh0u","colab_type":"code","colab":{}},"source":["from collections import namedtuple\n","import numpy as np\n","import cvxpy as cp\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","from sklearn.datasets import make_blobs, make_circles, make_moons\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","from IPython.display import set_matplotlib_formats\n","%matplotlib inline\n","set_matplotlib_formats('svg')\n","from sklearn.svm import SVC\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"635ef383eb1bbac18475fa0ab7e67ff1","grade":false,"grade_id":"cell-d56011b32dec1274","locked":true,"schema_version":3,"solution":false,"task":false},"id":"LqMiOxyxLh0w","colab_type":"code","colab":{}},"source":["# Counter for figures\n","figcount = 0\n","\n","# Set the random seed for reproducing results\n","random_seed = 97 \n","np.random.seed(random_seed)\n","\n","# Colors to use for plotting\n","colors = [plt.cm.Paired(3), plt.cm.Paired(1), plt.cm.Paired(5)]\n","\n","# Data set namedtuple\n","DataSet = namedtuple(\"DataSet\", (\"X_train\", \"X_test\", \"y_train\", \"y_test\"))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"12ac15b3617b78882e249a17651849b3","grade":false,"grade_id":"cell-d07c53f9db327386","locked":true,"schema_version":3,"solution":false,"task":false},"id":"iV2oSmcGLh0y","colab_type":"text"},"source":["<a href=#objectives> [go to top] </a>\n","# Part 1: The SVM Problem <a name='svm_problem' />\n","The SVM optimization problem in matrix form is defined as follows:\n","\n","$$\\underset{\\mathbf{a}}{\\text{maximize}}\\ \\mathbb{1}_N^T\\mathbf{a} - \\frac{1}{2}\\mathbf{a}^T\\mathbf{P}\\mathbf{a}$$\n","$$\n","\\begin{split}\n","\\text{subject to}\\quad\\quad a_i &\\geq 0, \\quad i=1,\\ldots,N \\\\\n","\\mathbf{y}^T \\mathbf{a} &= 0\n","\\end{split}\n","$$\n","\n","with \n","\n","- $\\mathbb{1}_N = [1, 1, \\ldots 1]^T \\in \\mathbb{N}^{N}$\n","- $\\mathbf{P} = (\\mathbf{y}\\mathbf{y}^T) \\circ \\mathbf{K}$, where $(\\mathbf{y}\\mathbf{y}^T)$ is the [*outer product*](https://en.wikipedia.org/wiki/Outer_product) and $\\circ$ is the [*Hadamard product*](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)), also known as element wise matrix multiplication.\n","- $\\mathbf{K}$ is the *Gram matrix*. \n","\n","The accompanying [qp_notation_svm.pdf](qp_notation_svm.pdf) shows the full derivation that was used to convert the original problem into matrix form."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"38e612e4bf9e1ba78cae701afb4b822e","grade":false,"grade_id":"cell-acfea57c083db8ec","locked":true,"schema_version":3,"solution":false,"task":false},"id":"2jfLyGJxLh0z","colab_type":"text"},"source":["First we are going to look at a binary classification problem in which the data is linearly separable in the input space $\\mathbf{x}$ and where the dataset contains just four points. Most steps for this simple problem can be validated by hand, we highly recommend you do that.\n","\n","The functions in part 1 will be used throughout the notebook.\n","\n","In order to solve the SVM problem we are going to complete the following steps:\n","1. Define the linear kernel\n","2. Compute the Gram matrix $\\mathbf{K}$ and Matrix $\\mathbf{P}$\n","3. Solve the optmization problem to find $\\mathbf{a}$\n","4. Compute the support vectors\n","5. Compute $\\mathbf{w}$\n","6. Compute $b$\n","7. Define the decision function $f$ and a predictor for $y$"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"b9652fd6f63e7ae3dd470eecefac3b73","grade":false,"grade_id":"cell-e56ef34da062b07c","locked":true,"schema_version":3,"solution":false,"task":false},"id":"aTaMTuxjLh0z","colab_type":"code","colab":{}},"source":["def get_test_data_set():\n","    X_train = np.array([[1, 1],\n","                        [2, 2],\n","                        [3, 3],\n","                        [4, 4]])\n","    \n","    y_train = np.array([-1, -1, 1, 1]) # For SVM we need target values {-1,+1} \n","    X_test = np.array([[1.2, 2.3],\n","                       [2.5, 1.7],\n","                       [2.7, 3.2],\n","                       [3.5, 2.5]])\n","    y_test = np.array([-1, -1, 1, 1])\n","    \n","    return DataSet(X_train, X_test, y_train, y_test)\n","\n","def plot_data(ax, data_set, legend='upper left'):\n","    X_train, X_test, y_train, y_test = data_set\n","    \n","    # Scatter plotting the data, filtering them according the pos/neg values\n","    for y in [-1, 1]:        \n","        ax.scatter(X_train[y_train == y, 0], X_train[y_train == y, 1], \n","                   c=[colors[y]], \n","                   s=30, \n","                   label=r'$y={}$ (train)'.format(y))\n","        ax.scatter(X_test[y_test  == y, 0], X_test[y_test  == y, 1], \n","                   c=[colors[y]], \n","                   s=50, \n","                   marker='x', \n","                   label=r'$y={}$ (test)'.format(y))\n","    \n","    # Set Labels and Limits\n","    ax.set_xlabel(r'$x_0$')\n","    ax.set_ylabel(r'$x_1$')\n","    ax.set_xlim(min(X_train[:, 0].min(), X_test[:,0].min()) - 0.1, \n","                max(X_train[:, 0].max(), X_test[:,0].max()) + 0.1)\n","    ax.set_ylim(min(X_train[:, 1].min(), X_test[:,1].min()) - 0.1, \n","                max(X_train[:, 1].max(), X_test[:,1].max()) + 0.1)\n","    \n","    # Legend\n","    if legend is not None:\n","        pst = ax.legend(loc=legend, frameon=True)\n","        pst.get_frame().set_edgecolor('k')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"e10e83bef3062750620fc6bf98f0a560","grade":false,"grade_id":"cell-37ce02bc69658f51","locked":true,"schema_version":3,"solution":false,"task":false},"id":"1sjaNOi4Lh01","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":370},"outputId":"cac8efaf-8688-4a59-941d-498a9b06699c","executionInfo":{"status":"ok","timestamp":1585909195670,"user_tz":-120,"elapsed":892,"user":{"displayName":"David Kurz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe_wM_K4xbhRICUKcX-SppDNFL1Q7WyvevxsgB=s64","userId":"17311286808322757220"}}},"source":["# Get data set\n","test_data_set = get_test_data_set()\n","\n","# Plot data\n","plt.figure()\n","ax = plt.gca()\n","plot_data(ax, test_data_set)"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 385.78125 262.19625\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 385.78125 262.19625 \nL 385.78125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 224.64 \nL 378.58125 224.64 \nL 378.58125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 2.738613 \nC 0.726289 2.738613 1.422928 2.450055 1.936492 1.936492 \nC 2.450055 1.422928 2.738613 0.726289 2.738613 0 \nC 2.738613 -0.726289 2.450055 -1.422928 1.936492 -1.936492 \nC 1.422928 -2.450055 0.726289 -2.738613 0 -2.738613 \nC -0.726289 -2.738613 -1.422928 -2.450055 -1.936492 -1.936492 \nC -2.450055 -1.422928 -2.738613 -0.726289 -2.738613 0 \nC -2.738613 0.726289 -2.450055 1.422928 -1.936492 1.936492 \nC -1.422928 2.450055 -0.726289 2.738613 0 2.738613 \nz\n\" id=\"m25917d41b2\" style=\"stroke:#e31a1c;\"/>\n    </defs>\n    <g clip-path=\"url(#pc9e4c6bfb4)\">\n     <use style=\"fill:#e31a1c;stroke:#e31a1c;\" x=\"54.24375\" xlink:href=\"#m25917d41b2\" y=\"217.845\"/>\n     <use style=\"fill:#e31a1c;stroke:#e31a1c;\" x=\"158.86875\" xlink:href=\"#m25917d41b2\" y=\"149.895\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_2\">\n    <defs>\n     <path d=\"M -3.535534 3.535534 \nL 3.535534 -3.535534 \nM -3.535534 -3.535534 \nL 3.535534 3.535534 \n\" id=\"m05b19c5344\" style=\"stroke:#e31a1c;stroke-width:1.5;\"/>\n    </defs>\n    <g clip-path=\"url(#pc9e4c6bfb4)\">\n     <use style=\"fill:#e31a1c;stroke:#e31a1c;stroke-width:1.5;\" x=\"75.16875\" xlink:href=\"#m05b19c5344\" y=\"129.51\"/>\n     <use style=\"fill:#e31a1c;stroke:#e31a1c;stroke-width:1.5;\" x=\"211.18125\" xlink:href=\"#m05b19c5344\" y=\"170.28\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_3\">\n    <defs>\n     <path d=\"M 0 2.738613 \nC 0.726289 2.738613 1.422928 2.450055 1.936492 1.936492 \nC 2.450055 1.422928 2.738613 0.726289 2.738613 0 \nC 2.738613 -0.726289 2.450055 -1.422928 1.936492 -1.936492 \nC 1.422928 -2.450055 0.726289 -2.738613 0 -2.738613 \nC -0.726289 -2.738613 -1.422928 -2.450055 -1.936492 -1.936492 \nC -2.450055 -1.422928 -2.738613 -0.726289 -2.738613 0 \nC -2.738613 0.726289 -2.450055 1.422928 -1.936492 1.936492 \nC -1.422928 2.450055 -0.726289 2.738613 0 2.738613 \nz\n\" id=\"m50319f8583\" style=\"stroke:#1f78b4;\"/>\n    </defs>\n    <g clip-path=\"url(#pc9e4c6bfb4)\">\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"263.49375\" xlink:href=\"#m50319f8583\" y=\"81.945\"/>\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"368.11875\" xlink:href=\"#m50319f8583\" y=\"13.995\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_4\">\n    <defs>\n     <path d=\"M -3.535534 3.535534 \nL 3.535534 -3.535534 \nM -3.535534 -3.535534 \nL 3.535534 3.535534 \n\" id=\"mb635510c3b\" style=\"stroke:#1f78b4;stroke-width:1.5;\"/>\n    </defs>\n    <g clip-path=\"url(#pc9e4c6bfb4)\">\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;stroke-width:1.5;\" x=\"232.10625\" xlink:href=\"#mb635510c3b\" y=\"68.355\"/>\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;stroke-width:1.5;\" x=\"315.80625\" xlink:href=\"#mb635510c3b\" y=\"115.92\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"meb1e613f74\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.24375\" xlink:href=\"#meb1e613f74\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(46.292187 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.55625\" xlink:href=\"#meb1e613f74\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(98.604688 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"158.86875\" xlink:href=\"#meb1e613f74\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2.0 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(150.917188 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"211.18125\" xlink:href=\"#meb1e613f74\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.5 -->\n      <g transform=\"translate(203.229688 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"263.49375\" xlink:href=\"#meb1e613f74\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(255.542187 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"315.80625\" xlink:href=\"#meb1e613f74\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.5 -->\n      <g transform=\"translate(307.854687 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.11875\" xlink:href=\"#meb1e613f74\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4.0 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(360.167187 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- $x_0$ -->\n     <defs>\n      <path d=\"M 60.015625 54.6875 \nL 34.90625 27.875 \nL 50.296875 0 \nL 39.984375 0 \nL 28.421875 21.6875 \nL 8.296875 0 \nL -2.59375 0 \nL 24.3125 28.8125 \nL 10.015625 54.6875 \nL 20.3125 54.6875 \nL 30.8125 34.90625 \nL 49.125 54.6875 \nz\n\" id=\"DejaVuSans-Oblique-120\"/>\n     </defs>\n     <g transform=\"translate(205.83125 252.916562)scale(0.1 -0.1)\">\n      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n      <use transform=\"translate(59.179688 -16.09375)scale(0.7)\" xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"maf1492c37c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#maf1492c37c\" y=\"217.845\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 221.644219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#maf1492c37c\" y=\"183.87\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(20.878125 187.669219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#maf1492c37c\" y=\"149.895\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(20.878125 153.694219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#maf1492c37c\" y=\"115.92\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 2.5 -->\n      <g transform=\"translate(20.878125 119.719219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#maf1492c37c\" y=\"81.945\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 3.0 -->\n      <g transform=\"translate(20.878125 85.744219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#maf1492c37c\" y=\"47.97\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 3.5 -->\n      <g transform=\"translate(20.878125 51.769219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#maf1492c37c\" y=\"13.995\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 4.0 -->\n      <g transform=\"translate(20.878125 17.794219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- $x_1$ -->\n     <g transform=\"translate(14.798438 121.27)rotate(-90)scale(0.1 -0.1)\">\n      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n      <use transform=\"translate(59.179688 -16.09375)scale(0.7)\" xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 224.64 \nL 43.78125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 378.58125 224.64 \nL 378.58125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 224.64 \nL 378.58125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 378.58125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 50.78125 74 \nL 153.88125 74 \nQ 155.88125 74 155.88125 72 \nL 155.88125 14.2 \nQ 155.88125 12.2 153.88125 12.2 \nL 50.78125 12.2 \nQ 48.78125 12.2 48.78125 14.2 \nL 48.78125 72 \nQ 48.78125 74 50.78125 74 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#000000;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"PathCollection_5\">\n     <g>\n      <use style=\"fill:#e31a1c;stroke:#e31a1c;\" x=\"62.78125\" xlink:href=\"#m25917d41b2\" y=\"21.175\"/>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- $y=-1$ (train) -->\n     <defs>\n      <path d=\"M 24.8125 -5.078125 \nQ 18.5625 -15.578125 14.625 -18.1875 \nQ 10.6875 -20.796875 4.59375 -20.796875 \nL -2.484375 -20.796875 \nL -0.984375 -13.28125 \nL 4.203125 -13.28125 \nQ 7.953125 -13.28125 10.59375 -11.234375 \nQ 13.234375 -9.1875 16.5 -3.21875 \nL 19.28125 2 \nL 7.171875 54.6875 \nL 16.703125 54.6875 \nL 25.78125 12.796875 \nL 50.875 54.6875 \nL 60.296875 54.6875 \nz\n\" id=\"DejaVuSans-Oblique-121\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <g transform=\"translate(80.78125 23.8)scale(0.1 -0.1)\">\n      <use transform=\"translate(0 0.015625)\" xlink:href=\"#DejaVuSans-Oblique-121\"/>\n      <use transform=\"translate(78.662109 0.015625)\" xlink:href=\"#DejaVuSans-61\"/>\n      <use transform=\"translate(201.416016 0.015625)\" xlink:href=\"#DejaVuSans-8722\"/>\n      <use transform=\"translate(304.6875 0.015625)\" xlink:href=\"#DejaVuSans-49\"/>\n      <use transform=\"translate(368.310547 0.015625)\" xlink:href=\"#DejaVuSans-32\"/>\n      <use transform=\"translate(400.097656 0.015625)\" xlink:href=\"#DejaVuSans-40\"/>\n      <use transform=\"translate(439.111328 0.015625)\" xlink:href=\"#DejaVuSans-116\"/>\n      <use transform=\"translate(478.320312 0.015625)\" xlink:href=\"#DejaVuSans-114\"/>\n      <use transform=\"translate(519.433594 0.015625)\" xlink:href=\"#DejaVuSans-97\"/>\n      <use transform=\"translate(580.712891 0.015625)\" xlink:href=\"#DejaVuSans-105\"/>\n      <use transform=\"translate(608.496094 0.015625)\" xlink:href=\"#DejaVuSans-110\"/>\n      <use transform=\"translate(671.875 0.015625)\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"PathCollection_6\">\n     <g>\n      <use style=\"fill:#e31a1c;stroke:#e31a1c;stroke-width:1.5;\" x=\"62.78125\" xlink:href=\"#m05b19c5344\" y=\"35.875\"/>\n     </g>\n    </g>\n    <g id=\"text_18\">\n     <!-- $y=-1$ (test) -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(80.78125 38.5)scale(0.1 -0.1)\">\n      <use transform=\"translate(0 0.125)\" xlink:href=\"#DejaVuSans-Oblique-121\"/>\n      <use transform=\"translate(78.662109 0.125)\" xlink:href=\"#DejaVuSans-61\"/>\n      <use transform=\"translate(201.416016 0.125)\" xlink:href=\"#DejaVuSans-8722\"/>\n      <use transform=\"translate(304.6875 0.125)\" xlink:href=\"#DejaVuSans-49\"/>\n      <use transform=\"translate(368.310547 0.125)\" xlink:href=\"#DejaVuSans-32\"/>\n      <use transform=\"translate(400.097656 0.125)\" xlink:href=\"#DejaVuSans-40\"/>\n      <use transform=\"translate(439.111328 0.125)\" xlink:href=\"#DejaVuSans-116\"/>\n      <use transform=\"translate(478.320312 0.125)\" xlink:href=\"#DejaVuSans-101\"/>\n      <use transform=\"translate(539.84375 0.125)\" xlink:href=\"#DejaVuSans-115\"/>\n      <use transform=\"translate(591.943359 0.125)\" xlink:href=\"#DejaVuSans-116\"/>\n      <use transform=\"translate(631.152344 0.125)\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"PathCollection_7\">\n     <g>\n      <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"62.78125\" xlink:href=\"#m50319f8583\" y=\"50.575\"/>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- $y=1$ (train) -->\n     <g transform=\"translate(80.78125 53.2)scale(0.1 -0.1)\">\n      <use transform=\"translate(0 0.015625)\" xlink:href=\"#DejaVuSans-Oblique-121\"/>\n      <use transform=\"translate(78.662109 0.015625)\" xlink:href=\"#DejaVuSans-61\"/>\n      <use transform=\"translate(181.933594 0.015625)\" xlink:href=\"#DejaVuSans-49\"/>\n      <use transform=\"translate(245.556641 0.015625)\" xlink:href=\"#DejaVuSans-32\"/>\n      <use transform=\"translate(277.34375 0.015625)\" xlink:href=\"#DejaVuSans-40\"/>\n      <use transform=\"translate(316.357422 0.015625)\" xlink:href=\"#DejaVuSans-116\"/>\n      <use transform=\"translate(355.566406 0.015625)\" xlink:href=\"#DejaVuSans-114\"/>\n      <use transform=\"translate(396.679688 0.015625)\" xlink:href=\"#DejaVuSans-97\"/>\n      <use transform=\"translate(457.958984 0.015625)\" xlink:href=\"#DejaVuSans-105\"/>\n      <use transform=\"translate(485.742188 0.015625)\" xlink:href=\"#DejaVuSans-110\"/>\n      <use transform=\"translate(549.121094 0.015625)\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"PathCollection_8\">\n     <g>\n      <use style=\"fill:#1f78b4;stroke:#1f78b4;stroke-width:1.5;\" x=\"62.78125\" xlink:href=\"#mb635510c3b\" y=\"65.275\"/>\n     </g>\n    </g>\n    <g id=\"text_20\">\n     <!-- $y=1$ (test) -->\n     <g transform=\"translate(80.78125 67.9)scale(0.1 -0.1)\">\n      <use transform=\"translate(0 0.125)\" xlink:href=\"#DejaVuSans-Oblique-121\"/>\n      <use transform=\"translate(78.662109 0.125)\" xlink:href=\"#DejaVuSans-61\"/>\n      <use transform=\"translate(181.933594 0.125)\" xlink:href=\"#DejaVuSans-49\"/>\n      <use transform=\"translate(245.556641 0.125)\" xlink:href=\"#DejaVuSans-32\"/>\n      <use transform=\"translate(277.34375 0.125)\" xlink:href=\"#DejaVuSans-40\"/>\n      <use transform=\"translate(316.357422 0.125)\" xlink:href=\"#DejaVuSans-116\"/>\n      <use transform=\"translate(355.566406 0.125)\" xlink:href=\"#DejaVuSans-101\"/>\n      <use transform=\"translate(417.089844 0.125)\" xlink:href=\"#DejaVuSans-115\"/>\n      <use transform=\"translate(469.189453 0.125)\" xlink:href=\"#DejaVuSans-116\"/>\n      <use transform=\"translate(508.398438 0.125)\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc9e4c6bfb4\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"cdbb96be7ba80a719b982c9799a35670","grade":false,"grade_id":"cell-a52115e4d69cdb0b","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ybsCx61HLh03","colab_type":"text"},"source":["### Task 1.1: Linear Kernel\n","It is clear that the data is linearly separable in the input space $\\mathbf{x}$. Therefore we do not need to transform our data using some feature mapping, i.e., $\\phi(\\mathbf{x}) = \\mathbf{x}$. The *linear kernel* is the kernel associated with $\\phi(\\mathbf{x}) = \\mathbf{x}$. The first task is to derive the linear kernel and write a function that computes it."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"112f80fc1e737086cdb8524efa4b04c2","grade":false,"grade_id":"cell-c85818ef313e377d","locked":false,"schema_version":3,"solution":true,"task":false},"id":"qfFS0trdLh03","colab_type":"code","colab":{}},"source":["def linear_kernel(x_i, x_j):\n","    \"\"\"\n","    Compute the linear kernel between two arrays of data.\n","    \n","    :param x_i: (type: numpy array)\n","    :param x_j: (type: numpy array)\n","    :returns:   linear kernel, (type: float or numpy array)\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    #raise NotImplementedError()\n","    k = np.dot(x_i, x_j.T)\n","    return k\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"5fe994875864c4c4ad2fa13e4550775f","grade":true,"grade_id":"cell-2598323f30284e8c","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"eQOcdHu7Lh06","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ffd76c1b-5ce7-4fd3-be48-9d4210a4f29a","executionInfo":{"status":"ok","timestamp":1585909201675,"user_tz":-120,"elapsed":655,"user":{"displayName":"David Kurz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe_wM_K4xbhRICUKcX-SppDNFL1Q7WyvevxsgB=s64","userId":"17311286808322757220"}}},"source":["x_i = np.array([1, 2, 3])\n","x_j = np.array([1, 1, 1])\n","\n","assert linear_kernel(x_i, x_i) == 14\n","assert linear_kernel(x_i, x_j) == 6\n","assert linear_kernel(x_j, x_j) == 3\n","\n","\n","print(linear_kernel(x_i,x_j))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"5494166b2d15c6d67fbba6d98012d8d5","grade":false,"grade_id":"cell-6f6a9634d36ab0a5","locked":true,"schema_version":3,"solution":false,"task":false},"id":"wAwaMuCdLh09","colab_type":"text"},"source":["### Task 1.2: Gram Matrix and Matrix P\n","Now that we have our kernel we can start defining our optimization problem. For that we need tot compute the Gram matrix $\\mathbf{K}$ and the matrix $\\mathbf{P} = (\\mathbf{y}\\mathbf{y}^T) \\circ \\mathbf{K}$."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"398670eea5809ee19ef4606cb547e9fc","grade":false,"grade_id":"cell-25d70ba1bc77fee9","locked":false,"schema_version":3,"solution":true,"task":false},"id":"VxCkPYXTLh09","colab_type":"code","colab":{}},"source":["def compute_gram_matrix(X, kernel=linear_kernel):\n","    \"\"\"\n","    Compute the Gram matrix as defined in the slides and the associated pdf.\n","    \n","    Remember that X = [x[0], x[1], ..., x[N]]^T\n","    \n","    :param X:      training values (type: numpy array of shape (N, n_features))\n","    :param kernel: kernel (type: function or callable object)\n","    :returns:      Gram matrix (type: numpy array of shape (N, N))\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    K = np.dot(X.T,X)\n","    return K"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"88b6448b1bb28915b31b45967461572a","grade":false,"grade_id":"cell-4cabb15a5d28e752","locked":false,"schema_version":3,"solution":true,"task":false},"id":"B0Xuh5YzLh0_","colab_type":"code","colab":{}},"source":["def compute_P(K, y):\n","    \"\"\"\n","    Compute matrix P.\n","    \n","    :param K: Gram matrix (type: numpy array of shape (N, N))\n","    :param y: target values (type: numpy array of shape (N,))\n","    :returns: matrix P (type: numpy array of shape(N, N))\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    #raise NotImplementedError()\n","    a = np.dot(y,y.T)\n","    P = K.dot(a)\n","    return P"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c089e901ac36d51eedb63b3af7ec3b83","grade":true,"grade_id":"cell-8672c5f57e1ac374","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"FaTFRTS2Lh1B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":565},"outputId":"43a91b24-5b39-4b8a-fc7d-e61eac056e31","executionInfo":{"status":"error","timestamp":1585911013258,"user_tz":-120,"elapsed":828,"user":{"displayName":"David Kurz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe_wM_K4xbhRICUKcX-SppDNFL1Q7WyvevxsgB=s64","userId":"17311286808322757220"}}},"source":["K_true = np.asarray([[2,  4,  6,  8],\n","                     [4,  8, 12, 16],\n","                     [6, 12, 18, 24],\n","                     [8, 16, 24, 32]])\n","P_true = np.asarray([[ 2,   4,  -6,  -8],\n","                     [ 4,   8, -12, -16],\n","                     [-6, -12,  18,  24],\n","                     [-8, -16,  24,  32]])\n","\n","K = compute_gram_matrix(test_data_set.X_train, linear_kernel)\n","print(\"K:\")\n","print(K)\n","\n","P = compute_P(K, test_data_set.y_train)\n","print(\"\\nP:\")\n","print(P)\n","\n","assert np.allclose(K, K_true)\n","assert np.allclose(P, P_true)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["K:\n","[[30 30]\n"," [30 30]]\n","\n","P:\n","[[120 120]\n"," [120 120]]\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-08a0653066b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \"\"\"\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mequal_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[0myfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m         \u001b[0mfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxfin\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0myfin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mwithin_tol\u001b[0;34m(x, y, atol, rtol)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2246\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2) (4,4) "]}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"0c56757657ea0cfab252ea7790887373","grade":false,"grade_id":"cell-126ea2f38f1b24ae","locked":true,"schema_version":3,"solution":false,"task":false},"id":"WGkNHtL4Lh1E","colab_type":"text"},"source":["### Task 1.3: Solving the Optimization\n","Now it is time to do solve the SVM optimization problem using the functions you have defined above. Remember that the optmization problem is:\n","\n","$$\\underset{\\mathbf{a}}{\\text{maximize}}\\ \\mathbb{1}_N^T\\mathbf{a} - \\frac{1}{2}\\mathbf{a}^T\\mathbf{P}\\mathbf{a}$$\n","$$\n","\\begin{split}\n","\\text{subject to}\\quad\\quad a_i &\\geq 0, \\quad i=1,\\ldots,N \\\\\n","\\mathbf{y}^T \\mathbf{a} &= 0\n","\\end{split}\n","$$\n","\n","We don't want you to be spending to much time on having to figure out the `cvxpy` library, therefore the `optimize_svm` function is given. Go through the code to validate for your self what is happening and what each function means. Also have a look at the [cvxpy documentation](https://www.cvxpy.org/) or use the build in documentation viewer (run cell below for example)."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"ba50b175f073090c7b7fcf6ae1265880","grade":false,"grade_id":"cell-d25649a085759c0f","locked":true,"schema_version":3,"solution":false,"task":false},"id":"JUVtpCobLh1F","colab_type":"code","colab":{}},"source":["cp.quad_form?"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"a91cc9ae402244976bca5eef539f8455","grade":false,"grade_id":"cell-1ace34f8625bc9c5","locked":true,"schema_version":3,"solution":false,"task":false},"id":"VC3pQ33sLh1H","colab_type":"code","colab":{}},"source":["def optimize_svm(X, y, kernel=linear_kernel):\n","    \"\"\"\n","    Solves the the quadratic programming problem.\n","    \n","    The optimization does not always succeed, this can\n","    have several causes. \n","    \n","    When you get the error that the problem is not DCP \n","    we recommend trying different hyperparameters or a \n","    different kernel. Often the reason for this problem\n","    is that the data is not linearly separable in the \n","    feature space.\n","    \n","    Another error that can occur is that the solver\n","    was not able to find a solution. In this case, run\n","    the optimization again. Sometimes it was just some\n","    initialization error within the solver. If the solver\n","    keeps failing to solve the problem you have to change\n","    the hyperparameters or kernel.\n","    \n","    The main reason for problems however is wrongly \n","    implemented methods. So step one should always be,\n","    check your implementation.\n","    \n","    :param X:      training values (type: numpy array of shape (N, n_features))\n","    :param y:      target values (type: numpy array of shape (N,))\n","    :param kernel: kernel function (type: function or callable object)\n","    :returns:      Lagrangian multipliers (type: numpy array of shape (N,))\n","                   None if optimization fails\n","    \"\"\"\n","    N = y.shape[0]\n","    \n","    K = compute_gram_matrix(X, kernel)\n","    P = compute_P(K, y)\n","    P = 0.5 * (P + P.T) # make sure P is symmetric, increases stability of optimization\n","    \n","    a = cp.Variable((N,1))\n","    L = cp.sum(a) - 0.5 * cp.quad_form(a, P) \n","    \n","    constraints = [a >= 0, \n","                   a.T * y == 0]\n","\n","    objective = cp.Maximize(L)\n","    prob = cp.Problem(objective, constraints)\n","\n","    prob.solve(solver='ECOS')\n","    \n","    if a.value is None:\n","        print(\"No solution could be found, is the data linearly separable in the feature space?\")\n","        return None\n","    else:\n","        return a.value.reshape((-1,))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"7c5a8e6bfd5c564313628c91630cd4f4","grade":true,"grade_id":"cell-9af554f4a6a68967","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"XxBrPyBgLh1J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":388},"outputId":"e9e3695c-5a89-47b6-a59b-002ec28c46b3","executionInfo":{"status":"error","timestamp":1585911244834,"user_tz":-120,"elapsed":726,"user":{"displayName":"David Kurz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe_wM_K4xbhRICUKcX-SppDNFL1Q7WyvevxsgB=s64","userId":"17311286808322757220"}}},"source":["a = optimize_svm(test_data_set.X_train, test_data_set.y_train, linear_kernel)\n","\n","print(\"a:\", a)\n","\n","assert np.allclose(a, [0, 1, 1, 0])"],"execution_count":42,"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-641dfd0dca97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-2e2c7997f95b>\u001b[0m in \u001b[0;36moptimize_svm\u001b[0;34m(X, y, kernel)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquad_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     constraints = [a >= 0, \n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cvxpy/atoms/quad_form.py\u001b[0m in \u001b[0;36mquad_form\u001b[0;34m(x, P)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;31m# Check dimensions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for arguments.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Invalid dimensions for arguments."]}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"3846c2f45f28acc921f2a305cfffa7f2","grade":false,"grade_id":"cell-230945c40385cfd4","locked":true,"schema_version":3,"solution":false,"task":false},"id":"lVLi09iDLh1L","colab_type":"text"},"source":["### Task 1.4: Computing the Support Vectors\n","\n","##### Note on Numerical Values:\n","Since we are working with numerical optimization, results\n","will have small errors and cannot be compared directly. We \n","can work around this problem by using small thresholds. \n","\n","For example:\n","We have a true value `y = 1` and some numerical optimization \n","calculates an estimate `yhat = 1.0000001` for `y`. Comparing \n","using `y == yhat` gives back `False`. Instead we can use\n","`abs(y - yhat) < threshold` to circumvent the problem."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"b4873983ee705bcded2a0c24b98364b7","grade":false,"grade_id":"cell-ce6252c4682b6171","locked":false,"schema_version":3,"solution":true,"task":false},"id":"6wQNaBmJLh1L","colab_type":"code","colab":{}},"source":["def compute_svi(a, threshold=1e-5):\n","    \"\"\"\n","    Compute the indices of the support vectors.   \n","    \n","    :param a:         Lagrange multipliers (type: numpy array of shape (N,))\n","    :param threshold: threshold value (type: float)\n","    :returns:         indices of the support vectors (type: numpy array of shape (S,))\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    svi = SVC(C = 1e5, kernel = 'linear')\n","    svi.fit(a,y)\n","    svi.support(a)\n","    return svi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"63f3b40cec1352b7a1d75493fc1809b1","grade":true,"grade_id":"cell-d4b2aaa07f178ef5","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"sqjKbBOQLh1O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"f7494cc3-39d7-4b94-ec05-bc8b1a9e8b45","executionInfo":{"status":"error","timestamp":1585912704664,"user_tz":-120,"elapsed":655,"user":{"displayName":"David Kurz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe_wM_K4xbhRICUKcX-SppDNFL1Q7WyvevxsgB=s64","userId":"17311286808322757220"}}},"source":["svi = compute_svi(a)\n","print(\"svi:\", svi)\n","\n","support_vectors = test_data_set.X_train[svi]\n","print(\"support vectors:\")\n","print(support_vectors)\n","\n","assert np.allclose(svi, [1, 2])"],"execution_count":53,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-68e2a9535919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_svi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"svi:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msupport_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msvi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"support vectors:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"]}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"24a9e29423bc9094f9830421ba514942","grade":false,"grade_id":"cell-635fee4ce5cca4ef","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ZJ22LWlCLh1Q","colab_type":"text"},"source":["### Question 1: what do support vectors represent?\n","The SVM tries to find a decision boundary that separates two classes with the widest margin. For points on the decision boundary we know that the decision function equals zero:\n","\n","$$f(\\mathbf{x}) = \\mathbf{w}^T\\phi(\\mathbf{x}) + b = 0$$\n","\n","What is the value of the decision function for the support vectors?"]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"cell_type":"markdown","checksum":"4148f9009a9aab01de4d22faa221dc64","grade":true,"grade_id":"cell-dcaae8b35d07a5f5","locked":false,"points":1,"schema_version":3,"solution":true,"task":false},"id":"Q03Hsst1Lh1Q","colab_type":"text"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"fcde8fbbfbf9f20f85af90543b392a95","grade":false,"grade_id":"cell-09a20df6364bb1e0","locked":true,"schema_version":3,"solution":false,"task":false},"id":"o12mEI87Lh1Q","colab_type":"text"},"source":["### Task 1.5: Computing $\\mathbf{w}$\n","Remember from the VO that we can find an expression for $\\mathbf{w}$ by solving:\n","\n","$\\frac{\\partial L}{\\partial \\mathbf{w}} = 0$\n","\n","(This does require the formulation of $L$ that contains the variable $\\mathbf{w}$, see the VO slides for more info)"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"e4fac3f425fc62a358ee1779c8b7a4ca","grade":false,"grade_id":"cell-e1e6cc3a2df3c1a4","locked":false,"schema_version":3,"solution":true,"task":false},"id":"mD6GoSDoLh1R","colab_type":"code","colab":{}},"source":["def compute_w(a, y, X):\n","    \"\"\"\n","    Compute weight vector w\n","    \n","    :param a: Lagrange multipliers (type: numpy array of shape (N,))\n","    :param y: target values (type: numpy array of shape(N,))\n","    :param x: training vectors (type: numpy array of shape(N, n_features))\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    \n","    return w"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"7465df790eb0726878161d858876ba5a","grade":true,"grade_id":"cell-5380efb8979b2d59","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"KvtVeL3ULh1T","colab_type":"code","colab":{}},"source":["w = compute_w(a, test_data_set.y_train, test_data_set.X_train)\n","print(\"w:\", w)\n","\n","assert np.allclose(w, [1, 1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"ce797926756feac76c687e29654b192f","grade":false,"grade_id":"cell-b3a39d9c71c15faa","locked":true,"schema_version":3,"solution":false,"task":false},"id":"C4QCOa6-Lh1V","colab_type":"text"},"source":["### Task 1.6: Computing $b$\n","The decision function is defined as:\n","\n","$$f(\\mathbf{x}) = \\mathbf{w}^T\\phi(\\mathbf{x}) + b$$\n","\n","for the support vectors $\\mathbf{x}_s \\in \\mathcal{S}$, where $\\mathcal{S}$ denotes the set of all support vectors, we know that: \n","\n","$$f(\\mathbf{x_s}) = \\mathbf{w}^T\\phi(\\mathbf{x_s}) + b = y_s$$ \n","\n","the values for $\\mathbf{w}$ and $\\mathbf{x}_s$ are known, so we can solve for $b$:\n","\n","$$b = y_s - \\mathbf{w}^T\\phi(\\mathbf{x_s})$$\n","\n","But which support vector $\\mathbf{x}_s$ do we use? It turns out that just using one value might result in stability issues. A commonly used solution is to average over all support vectors $\\mathcal{S}$:\n","\n","$$b = \\frac{1}{|\\mathcal{S}|}\\sum_{i \\in \\mathcal{S}}y_i - \\mathbf{w}^T\\phi(\\mathbf{x}_i)$$\n","\n","One more issue remains, our expression for $b$ contains the feature $\\phi(\\mathbf{x}_i)$. One nice property of SVMs is that the feature mapping $\\phi$ does not have to be known, but only a kernel $k(\\mathbf{x}_i, \\mathbf{x}_j)$ that is valid for $\\phi$.\n","\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"7d2a93bc2e1c50ce7c25275dbc6d3588","grade":false,"grade_id":"cell-91f4773f600c3ce4","locked":true,"schema_version":3,"solution":false,"task":false},"id":"73kKcD7NLh1V","colab_type":"text"},"source":["### Question 2: What is an advantage of using $k$ instead of $\\phi$?\n","Remember that a kernel function is defined as $k(\\mathbf{x}_i, \\mathbf{x}_j) = \\phi(\\mathbf{x}_i)^T\\phi(\\mathbf{x}_j)$. Tip: how does the feature mapping $\\phi$ of, for example, $k(\\mathbf{x}_i, \\mathbf{x}_j) = (\\mathbf{x}_i^T\\mathbf{x}_j)^2$ look?"]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"cell_type":"markdown","checksum":"20c13c06f3badb666fae4addec3c088a","grade":true,"grade_id":"cell-045cc4cd7fbef940","locked":false,"points":1,"schema_version":3,"solution":true,"task":false},"id":"5VqkEChxLh1W","colab_type":"text"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"aaefc1f05d0bfc2b6cec1b6e2bde4fc1","grade":false,"grade_id":"cell-981595484b3b2723","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ofMyg7IpLh1W","colab_type":"text"},"source":["Rewrite the expression for $b$ into a form that uses the kernel function $k(\\mathbf{x}_i, \\mathbf{x}_j)$ instead of $\\phi(\\mathbf{x}_i)$. Use the rewritten expression in the tasks below."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"7e777af28d44d1b21294cdec8770d113","grade":false,"grade_id":"cell-8a0764aab7e7b999","locked":false,"schema_version":3,"solution":true,"task":false},"id":"KBu2OMWrLh1W","colab_type":"code","colab":{}},"source":["def compute_b(a_sv, y_sv, support_vectors, kernel=linear_kernel):\n","    \"\"\"\n","    Compute the bias variable `b` using the averaging approach.\n","    \n","    :param a_sv:            lagrange multipliers corresponding to the support vectors \n","                            (type: numpy array of shape (n_support_vectors,))\n","    :param y_sv:            target values corresponding to the support vectors\n","                            (type: numpy array of shape (n_support_vectors,))\n","    :param support_vectors: support vectors (type: numpy array of shape (n_support_vectors, n_features))\n","    :param kernel:          kernel (type: function or callable object)\n","    :returns:               bias variable (type: float)\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    \n","    return b"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"da57253baa3d8ae7fde8fbdf0a55dc26","grade":false,"grade_id":"cell-0329434305944090","locked":true,"schema_version":3,"solution":false,"task":false},"id":"C2-I0E7vLh1Z","colab_type":"text"},"source":["For a linear kernel the feature mapping is particularly easy: $\\phi(\\mathbf{x}) = \\mathbf{x}$. We will use this for evaluating the function `compute_b` by comparing the results with the expression:\n","\n","$$b = \\frac{1}{|\\mathcal{S}|}\\sum_{i \\in \\mathcal{S}}y_i - \\mathbf{w}^T\\mathbf{x}_i$$\n","\n","Solve this exercise by hand an add the solution in the cell below:"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"ada99a42211c7e6a8453af3419db2357","grade":false,"grade_id":"cell-c34339e046e9fd2c","locked":false,"schema_version":3,"solution":true,"task":false},"id":"Ol2rNY1nLh1Z","colab_type":"code","colab":{}},"source":["def b_features():\n","    \"\"\"\n","    Return the value you found by solving the equation above.\n","    \n","    Simply write `return VALUE_FOR_B`\n","    \n","    :returns: bias b (type: float)\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c33d0e8b388eddd2a05e5c87fde6108e","grade":true,"grade_id":"cell-47532b4820466b3e","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"6ckD3nlJLh1b","colab_type":"code","colab":{}},"source":["a_sv = a[svi]\n","y_sv = test_data_set.y_train[svi]\n","\n","b = compute_b(a_sv, y_sv, support_vectors, linear_kernel)\n","print(\"b:\", b)\n","\n","assert abs(b - b_features()) < 1e-5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"51c31f4c2904bf8d6b138bc5b8ee1448","grade":false,"grade_id":"cell-e1f17d0bb7359119","locked":true,"schema_version":3,"solution":false,"task":false},"id":"DE5EqirwLh1e","colab_type":"text"},"source":["### Task 1.7: Decision Function and Prediction \n","We now have all the components for our model, the next step is to use them for making predictions. We split the prediction into two parts, first part is the decision function $f$. The predictor can use the decision function for making predictions. We will also define an accuracy metric for evaluating the accuracy of our model on a test set."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"c800dbe04114cb0e241024a1d831ca92","grade":false,"grade_id":"cell-8cd66669619f5530","locked":false,"schema_version":3,"solution":true,"task":false},"id":"-IE3MQvKLh1f","colab_type":"code","colab":{}},"source":["def decision_function(x, a, y, X, b, kernel=linear_kernel):\n","    \"\"\"\n","    The decision function tells us on which side of the decision boundary \n","    generated by `f` a sample `x` is located\n","    \n","    :param x:      input sample (type: numpy array of shape (n_features,))\n","    :param a:      lagrange multipliers (type: numpy array of shape (M,))\n","    :param y:      target values (type: numpy array of shape (M,))\n","    :param X:      training values (type: numpy array of shape(M, n_features))\n","    :param b:      bias variable (type: float)\n","    :param kernel: kernel (type: function or callable object)\n","    :returns:      decision function value (type: float)\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    \n","    return f\n","    \n","    \n","def predict(x, a, y, X, b, kernel=linear_kernel):\n","    \"\"\"\n","    Predicts the target value `y=1` or `y=-1` for a sample `x`.\n","    \n","    Tip: use the decision function defined above.\n","    \n","    :param x:      input sample (type: numpy array of shape (n_features,))\n","    :param a:      lagrange multipliers (type: numpy array of shape (M,))\n","    :param y:      target values (type: numpy array of shape (M,))\n","    :param X:      training values (type: numpy array of shape(M, n_features))\n","    :param b:      bias variable (type: float)\n","    :param kernel: kernel (type: function or callable object)\n","    :returns:      prediction yhat={-1, 1} (type: int or float)\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    \n","    return yhat\n","\n","\n","def accuracy(y, yhat):\n","    \"\"\"\n","    Calculates the accuracy as the number of correctly predicted\n","    target divided by the total number of predictions.\n","        \n","    :param y:    actual target values (type: numpy array of shape (M,))\n","    :param yhat: predicted target values (type: numpy array of shape(M,))\n","    :returns:    accuracy score (type: float)\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    \n","    return score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c0568dcf698a9b8bc2e3fa69e956e33b","grade":true,"grade_id":"cell-f9e12abaee390cb4","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"Y26ZcfUELh1h","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = test_data_set\n","f_test = np.asarray([-1.5, -0.8, 0.9, 1.])\n","\n","# Get values decision function\n","f = decision_function(X_test, a, y_train, X_train, b, linear_kernel)\n","print(\"f:\", f)\n","\n","# Get values prediction\n","y_pred = predict(X_test, a, y_train, X_train, b, linear_kernel)\n","print(\"y:\", y_pred)\n","\n","# Validate accuracy\n","score = accuracy(y_test, y_pred)\n","print(\"score:\", score)\n","\n","assert np.allclose(f, f_test)\n","assert np.allclose(y_pred, y_test)\n","assert abs(score - 1.0) < 1e-5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"a7e6bb846a44152df26fc89c8bbdf236","grade":false,"grade_id":"cell-d9909076f88e45ee","locked":true,"schema_version":3,"solution":false,"task":false},"id":"CFA-7Uw0Lh1l","colab_type":"text"},"source":["### Question 3: Should we use `a`, `y` and `X`  or `sv_a`, `sv_y` and `support_vectors`?\n","Lets look at the following functions we have defined in the previous tasks: `compute_w`, `compute_b`, `decision_function` and `predict`. \n","\n","When we computed $b$ it is clear from the theory we have to use the support vectors (`support_vectors`, `sv_a` and `sv_y`). But when we called the other three functions we used the full dataset (`X`, `a` and `y`), wouldn't it be enough to only use the support vectors for these three functions as well? Motivate your answer."]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"cell_type":"markdown","checksum":"b406952202deac78d3ca3389bb8f8298","grade":true,"grade_id":"cell-af898a3b2cd2d281","locked":false,"points":1,"schema_version":3,"solution":true,"task":false},"id":"ADH-HpTkLh1l","colab_type":"text"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"e12bb8cae0e881c1bd6a58ce0851a1d3","grade":false,"grade_id":"cell-eaebb4a8d82c7edc","locked":true,"schema_version":3,"solution":false,"task":false},"id":"B5ZTiNQoLh1m","colab_type":"text"},"source":["We now have now have all everything for our SVM classifier. Let's see what the classifier has learned by updating our figure. Plotting results is useful for interpretating what your model has actually learned, especially during development and implementation of your method. For high dimensional data this becomes difficult of course.\n","\n","In the plots, *dots* indicate training data and *stars* test data. The decision boundary is denoted be a *black line* and the *widest margin* by dotted lines. You don't have to understand how al the functions for generating the plots work."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"fbd328ec5e0317ee44cbbbb631166a61","grade":false,"grade_id":"cell-e98ea6516ca467ae","locked":true,"schema_version":3,"solution":false,"task":false},"id":"_qRKUhEGLh1m","colab_type":"code","colab":{}},"source":["plt.figure()\n","ax = plt.gca()\n","\n","# Plot data\n","plot_data(ax, test_data_set)\n","\n","# plot support vectors\n","ax.scatter(support_vectors[:, 0], support_vectors[:, 1], s=100,\n","           linewidth=1, facecolors='none', edgecolors='k')\n","\n","# plot the decision function\n","\n","xlim = ax.get_xlim()\n","ylim = ax.get_ylim()\n","\n","## create grid to evaluate model\n","xx = np.linspace(xlim[0], xlim[1], 30)\n","yy = np.linspace(ylim[0], ylim[1], 30)\n","YY, XX = np.meshgrid(yy, xx)\n","xy = np.vstack([XX.ravel(), YY.ravel()]).T\n","\n","margins = []\n","for _x in xy:\n","    margins.append(decision_function(_x, a_sv, y_sv, support_vectors, b))\n","margins = np.asarray(margins).reshape(XX.shape)\n","Z = np.zeros(margins.shape)\n","Z[margins < 0] = -1\n","Z[margins >= 0] = 1\n","\n","## plot decision boundary and margins   \n","ax.contour(XX, YY, margins, colors='k', levels=[-1, 0, 1], alpha=0.5,\n","               linestyles=['--', '-', '--'])\n","ax.contourf(XX, YY, Z, alpha=0.1, colors=[colors[-1], colors[1]])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"b4c3b857ee192be3501542cd594b57d3","grade":false,"grade_id":"cell-201ab227ea94e34f","locked":true,"schema_version":3,"solution":false,"task":false},"id":"_dUYbu7BLh1p","colab_type":"text"},"source":["The *black line* is our decision boundary, all samples above the line get $y=1$ (brown) from our predictor and all values below the line $y=-1$ (blue). The *dashed line* indicates the margin of our classifier, i.e., $f(\\mathbf{x}) = 1$, and our support vectors will lay on those lines, the support vectors are *encircled*. The *stars* are our test samples, which have been classified correctly."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"9083fdc1490d0e8b755e6b1e7315569b","grade":false,"grade_id":"cell-f76a3d5f6f7b309e","locked":true,"schema_version":3,"solution":false,"task":false},"id":"PCYMecIJLh1p","colab_type":"text"},"source":["## Combining All the Parts\n","In order to make working with our classifier we have combined all the parts into one class for you. For the rest of the notebook we will be using this class for constructing classifiers."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"0d589fa8f8999b6df4a038d0f58fbb02","grade":false,"grade_id":"cell-babda36e00e7631c","locked":true,"schema_version":3,"solution":false,"task":false},"id":"DvV5xhVqLh1p","colab_type":"code","colab":{}},"source":["class SVM:\n","    \n","    def __init__(self, kernel, threshold=1e-5):\n","        self.kernel = kernel\n","        self.threshold = threshold\n","        \n","        self.svi = None\n","        self.support_vectors = None\n","        self.sv_y = None\n","        self.sv_a = None\n","        self.w = None\n","        self.b = None\n","        \n","    def optmize(self, X, y):\n","        return optimize_svm(X, y, self.kernel)\n","        \n","    def fit(self, X, y):        \n","        # Perform optmization\n","        a = self.optmize(X, y)\n","        if a is None:\n","            return False\n","        \n","        # Determine support vectors (a != 0)\n","        self.svi = compute_svi(a)\n","        \n","        # Store support vector variables we need later\n","        self.support_vectors = X[self.svi]\n","        self.sv_y = y[self.svi]\n","        self.sv_a = a[self.svi]\n","        \n","        # Compute w\n","        self.w = compute_w(self.sv_a, self.sv_y, self.support_vectors)\n","\n","        # Compute b\n","        self.b = compute_b(self.sv_a, self.sv_y, self.support_vectors, kernel=self.kernel)\n","        \n","        return True\n","        \n","    def decision_function(self, x):\n","        if self.b is None:\n","            print(\"Model has not been trained yet, first run '{}.fit(X, y)'\".format(self.__class__.__name__))\n","            return None\n","        \n","        return decision_function(x, self.sv_a, self.sv_y, self.support_vectors, self.b, kernel=self.kernel)\n","    \n","    def predict(self, x):\n","        if self.b is None:\n","            print(\"Model has not been trained yet, first run '{}.fit(X, y)'\".format(self.__class__.__name__))\n","            return None\n","        \n","        return predict(x, self.sv_a, self.sv_y, self.support_vectors, self.b, kernel=self.kernel)\n","    \n","    def score(self, x, y):\n","        if self.b is None:\n","            print(\"Model has not been trained yet, first run '{}.fit(X, y)'\".format(self.__class__.__name__))\n","            return None\n","        \n","        yhat = self.predict(x)\n","        return accuracy_score(y, yhat)\n","    \n","    def plot_decision_boundary(self, ax):\n","        # plot support vectors\n","        ax.scatter(self.support_vectors[:, 0], self.support_vectors[:, 1], s=100,\n","                   linewidth=1, facecolors='none', edgecolors='k')\n","        \n","        # plot the decision function\n","        xlim = ax.get_xlim()\n","        ylim = ax.get_ylim()\n","\n","        ## create grid to evaluate model\n","        xx = np.linspace(xlim[0], xlim[1], 30)\n","        yy = np.linspace(ylim[0], ylim[1], 30)\n","        YY, XX = np.meshgrid(yy, xx)\n","        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n","        \n","        margins = []\n","        for _x in xy:\n","            margins.append(self.decision_function(_x))\n","        margins = np.asarray(margins).reshape(XX.shape)\n","        Z = np.zeros(margins.shape)\n","        Z[margins < 0] = -1\n","        Z[margins > 0] = 1\n","         \n","        ## plot decision boundary and margins   \n","        ax.contour(XX, YY, margins, colors='k', levels=[-1, 0, 1], alpha=0.5,\n","                       linestyles=['--', '-', '--'])\n","        ax.contourf(XX, YY, Z, alpha=0.1, colors=[colors[-1], colors[1]])\n","                "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"4d47d141042276a092188c30a8807dbc","grade":false,"grade_id":"cell-a46e6abad3b97e3f","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ZxJd2puyLh1r","colab_type":"text"},"source":["### Example using SVM Class"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"2e050324c495758f7aeb821d49a12813","grade":false,"grade_id":"cell-217383b718efdd97","locked":true,"schema_version":3,"solution":false,"task":false},"id":"XfJMBST4Lh1r","colab_type":"code","colab":{}},"source":["np.random.seed(231)\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(11,11))\n","gs = gridspec.GridSpec(2, 2)\n","gs.update(wspace=0.2, hspace=0.5)\n","\n","for i in range(4):\n","    print(\"Solving for data set {}\".format(i))\n","    # Generate random data\n","    X, y = make_blobs(40, centers=2, random_state=i+1)\n","    y[y == 0] = -1\n","    \n","    # Split data into train and test set\n","    data_set = DataSet(*train_test_split(X, y, test_size=0.3))\n","        \n","    # Plot data\n","    ax = plt.subplot(gs[i])\n","    legend = 'upper left' if i == 0 else None\n","    plot_data(ax, data_set, legend)\n","        \n","    # Create SVM with linear kernel\n","    svm = SVM(kernel=linear_kernel)\n","    \n","    # Fit the data\n","    success = svm.fit(data_set.X_train, data_set.y_train)\n","    if not success:\n","        continue\n","    \n","    # Validate on test set  \n","    score = svm.score(data_set.X_test, data_set.y_test)\n","        \n","    # Plot margins and predictions\n","    svm.plot_decision_boundary(ax)\n","    \n","    pad_text = -0.2\n","    ax.text(0.5, pad_text, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.075, \"# support vectors: {}\".format(len(svm.svi)), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.15, \"w: {}\".format(svm.w), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.225, \"b: {:.2}\".format(svm.b), size=12, ha=\"center\", transform=ax.transAxes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"121cf4d23f8445b7965ca966c31e7d58","grade":false,"grade_id":"cell-0995a402f183366e","locked":true,"schema_version":3,"solution":false,"task":false},"id":"JgIzScICLh1u","colab_type":"text"},"source":["<a href=#objectives> [go to top] </a>\n","# Part 2: Kernels <a name='kernels' />\n","So far we have only looked at data that is linearly separable in the input space $\\mathbf{x}$. But in most data sets that won't be the case, but it might be that the data is linearly separable in some higher dimensional space obtained using a feature mapping $\\phi$. Thanks to the *kernel trick* we don't have to actually transform our data into this high dimensional feature space, but instead only need the associated kernel function.\n","\n","Lets first generate some need data sets, which we will simply call data set `0` and data set `1`."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"39158ce25cc557a4c9c6ee4f08659550","grade":false,"grade_id":"cell-0ff6700a06000b2c","locked":true,"schema_version":3,"solution":false,"task":false},"id":"74Zs33geLh1u","colab_type":"code","colab":{}},"source":["np.random.seed(1)\n","n_samples = 500\n","data_sets_kernels = []\n","\n","def add_to_data_sets(X, y):\n","    y[y == 0] = -1\n","    data_set = DataSet(*train_test_split(X, y, test_size=0.3))\n","    data_sets_kernels.append(data_set)\n","\n","X, y = make_circles(n_samples, factor=0.5, noise=0.07)\n","add_to_data_sets(X, y)\n","\n","X, y = make_moons(n_samples, noise=0.1)\n","add_to_data_sets(X, y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"04b659d340e28ba3e2da8c535f70bb8d","grade":false,"grade_id":"cell-8ea9934302c06586","locked":true,"schema_version":3,"solution":false,"task":false},"id":"9xkydXLdLh1x","colab_type":"code","colab":{}},"source":["np.set_printoptions(precision=2)\n","plt.figure(figsize=(11,11))\n","gs = gridspec.GridSpec(2, 2)\n","gs.update(wspace=0.2, hspace=0.5)\n","\n","for i, data_set in enumerate(data_sets_kernels):        \n","    # Plot data\n","    ax = plt.subplot(gs[i])\n","    legend = 'upper right' if i == 1 else None\n","    plot_data(ax, data_set, legend)\n","    ax.text(0.5, -0.2, \"data set: {}\".format(i), size=12, ha=\"center\", transform=ax.transAxes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"10989d4a33c1b505b1f6ecf18541bf5a","grade":false,"grade_id":"cell-845e2b04f6d371ff","locked":true,"schema_version":3,"solution":false,"task":false},"id":"xydpKa07Lh1y","colab_type":"text"},"source":["### Task 2.1: Implement the Gaussian and Polynomial Kernel\n"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"eba764610679ae3a4c8b0b57eac6f0a7","grade":false,"grade_id":"cell-63139247bf0df8fe","locked":false,"schema_version":3,"solution":true,"task":false},"id":"QIt7171gLh1z","colab_type":"code","colab":{}},"source":["class GaussianKernel:\n","    \n","    def __init__(self, sigma):\n","        self.sigma = sigma\n","        \n","    def __call__(self, x_i, x_j):\n","        \"\"\"\n","        Compute the Gaussian kernel between two vectors.\n","        \n","        The `__call__` method allows us to use instantiated classes as if\n","        they are functions:\n","        \n","          gaussian_kernel = GaussianKernel(0.5)\n","          k = gaussian_kernel(x_i, x_j)\n","          \n","        \n","        :param x_i: (type: numpy array)\n","        :param x_j: (type: numpy array)\n","        :returns:   Gaussian kernel (type: float or numpy array)\n","        \"\"\"\n","        \n","        # YOUR CODE HERE\n","        raise NotImplementedError()\n","        \n","        return k\n","    \n","class PolynomialKernel:\n","    \n","    def __init__(self, c, degree):\n","        self.c = c\n","        self.degree = degree\n","        \n","    def __call__(self, x_i, x_j):\n","        \"\"\"\n","        Compute the polynomial kernel between two vectors.\n","        \n","        \n","        :param x_i: (type: numpy array)\n","        :param x_j: (type: numpy array)\n","        :returns:   Polynomial kernel (type: float or numpy array)\n","        \"\"\"\n","        \n","        # YOUR CODE HERE\n","        raise NotImplementedError()\n","        \n","        return k"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"5530343f5fc94140232ed38ba49213e2","grade":true,"grade_id":"cell-84a3d1c480a43d42","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"1nfa1JH3Lh11","colab_type":"code","colab":{}},"source":["gaussian_kernel = GaussianKernel(sigma=1.0)\n","\n","assert abs(gaussian_kernel(np.array([1, 2]), np.array([1, 2])) - 1.0) < 1e-3\n","assert abs(gaussian_kernel(np.array([1, 1]), np.array([0, 0])) - 0.368) < 1e-3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"251bc43403f0a2ce84ed5715a2dc2eef","grade":true,"grade_id":"cell-1c6426edf5c5d5a3","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"xvLouD-vLh12","colab_type":"code","colab":{}},"source":["polynomial_kernel = PolynomialKernel(c=2.0, degree=3)\n","\n","assert abs(polynomial_kernel(np.array([0, 0]), np.array([1, 0])) - 8.0) < 1e-3\n","assert abs(polynomial_kernel(np.array([1, 2]), np.array([1, 1])) - 125.0) < 1e-3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"9ed07e9e90d047d696ef15c3d1ae8893","grade":false,"grade_id":"cell-77ea7403c773454e","locked":true,"schema_version":3,"solution":false,"task":false},"id":"eXl4iussLh14","colab_type":"text"},"source":["### Task 2.2: Proof That the Polynomial Kernel is a Valid Kernel\n","During the exercise session of the VO you had to prove that the Gaussian kernel is a valid kernel. Do the same for the polynomial kernel with `degree=2.0` and abitrary `c`. Derive the associated feature mapping $\\phi({\\mathbf{x}})$ and write a function to compute the feature mapping. The function should accept an abitrary size for input vector $\\mathbf{x}$.\n","\n","Tip: first find the solution on a piece of paper when using $\\mathbf{x_i} = [x_1, x_2]$ and $\\mathbf{x_j} = [z_1, z_2]$. And then solve for $\\mathbf{x_i} = [x_1, x_2, x_3]$ and $\\mathbf{x_j} = [z_1, z_2, z_3]$. Look for a pattern."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"603ec70a05b3c15e4aba26ab879a1283","grade":false,"grade_id":"cell-1b26f5eb921612bb","locked":false,"schema_version":3,"solution":true,"task":false},"id":"I641aqmiLh15","colab_type":"code","colab":{}},"source":["def compute_polynomial_feature(x, c):\n","    \"\"\"\n","    Compute second degree polynomial feature.\n","    \n","    :param x: input sample (numpy array of shape (n_features_1,))\n","    :param c: constant (type: float)\n","    :returns: polynomial feature (type: numpy array of shape (n_features_2,))\n","    \"\"\"\n","    degree = 2\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    \n","    return phi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"4d4a08e1f07edb1f763876300c969f23","grade":true,"grade_id":"cell-25a67edd8ac11a1a","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"I86KcURLLh16","colab_type":"code","colab":{}},"source":["c = 2.0\n","polynomial_kernel = PolynomialKernel(c=c, degree=2)\n","\n","for i in range(3):\n","    x = np.arange(1, i+3)\n","    phi = compute_polynomial_feature(x, c)\n","    print(\"\")\n","    print(\"x_{}:\".format(i), x)\n","    print(\"phi(x_{}):\".format(i), phi)\n","    \n","    assert abs(np.dot(phi, phi) - polynomial_kernel(x, x)) < 1e-5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"4855c0d1d0bd322eaee83d4b656e3dab","grade":false,"grade_id":"cell-c06f5eaafdbf737e","locked":true,"schema_version":3,"solution":false,"task":false},"id":"9knR1r7yLh1-","colab_type":"text"},"source":["### Task 2.3: Choosing Appropriate Kernels\n","Return the appropriate kernel for each dataset in the function `choose_kernel` below."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"b7ab2c901994170910ffc0822b553a38","grade":true,"grade_id":"cell-530635b9bada75ce","locked":false,"points":1,"schema_version":3,"solution":true,"task":false},"id":"SWA-AO_kLh1-","colab_type":"code","colab":{}},"source":["def choose_kernel(data_set_id):\n","    \"\"\"\n","    Return an appropriate kernel for each data set.\n","    \n","    Don't forgot to instantiate your kernel before returning and\n","    choose appropriate hyper parameters:\n","    \n","      gaussian_kernel = GaussianKernel(sigma)\n","      return gaussian_kernel\n","    \n","    :param data_set_id: for which data set to return the kernel (type: int)\n","    \"\"\"\n","    if data_set_id == 0:\n","        \n","        # YOUR CODE HERE\n","        gaussian_kernel = GaussianKernel(sigma = 1.0)\n","        return gaussian_kernel\n","        #raise NotImplementedError()\n","        \n","    if data_set_id == 1:\n","        \n","        # YOUR CODE HERE\n","        polynomial_kernel = PolynomialKernel(c=2,degree=3)\n","        #raise NotImplementedError()\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"d48255932b560222121c97ef2d731e0f","grade":false,"grade_id":"cell-81db24b1eff4f913","locked":true,"schema_version":3,"solution":false,"task":false},"id":"5b9CU9GtLh2A","colab_type":"code","colab":{}},"source":["np.set_printoptions(precision=2)\n","plt.figure(figsize=(11,11))\n","gs = gridspec.GridSpec(2, 2)\n","gs.update(wspace=0.2, hspace=0.5)\n","\n","for i, data_set in enumerate(data_sets_kernels):\n","    print(\"solving for dataset {}\".format(i))\n","    \n","    # Plot data\n","    ax = plt.subplot(gs[i])\n","    legend = 'upper right' if i == 1 else None\n","    plot_data(ax, data_set, legend)\n","        \n","    # Create SVM\n","    kernel = choose_kernel(i)\n","    svm = SVM(kernel)\n","    \n","    # Fit the data\n","    success = svm.fit(data_set.X_train, data_set.y_train)\n","    if not success:\n","        continue\n","    \n","    # Validate on test set    \n","    score = svm.score(data_set.X_test, data_set.y_test)\n","        \n","    # Plot Results\n","    svm.plot_decision_boundary(ax)\n","    \n","    pad_text = -0.2\n","    ax.text(0.5, pad_text, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.075, \"# support vectors: {}\".format(len(svm.svi)), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.15, \"w: {}\".format(svm.w), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.225, \"b: {:.2}\".format(svm.b), size=12, ha=\"center\", transform=ax.transAxes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"cf0a4b43ad149fc4fb89740741a2837b","grade":false,"grade_id":"cell-d243573f3d0e8884","locked":true,"schema_version":3,"solution":false,"task":false},"id":"5ZwjegLeLh2C","colab_type":"text"},"source":["<a href=#objectives> [go to top] </a>\n","# Part 3: $\\nu$-SVM (Advanced)<a name='nu_svm' />\n","So far we have seen data sets that are linearly seperable in some feature space generated by a mapping $\\phi$. In real data this will often be the case, and the data overlaps or contains some outlier. The standard SVM implementation imposes strict margins, instead we would like to have soft-margins that can deal with this type of data. \n","\n","In other words, for strict margins we want the training data of one class to be strictly on one side of the decision boundary and the other class on the other side and no samples within the margins. For soft margins, we say it is ok if some data samples in our training set are on the wrong side of the boundary or within the margin.\n","\n","One such algorithm is the $\\nu$-SVM. As discussed in the VO, the $\\nu$-SVM problem is defined as follows:\n","\n","$$\\underset{\\mathbf{a}}{\\text{maximize}}\\ \\mathbb{1}_N^T\\mathbf{a} - \\frac{1}{2}\\mathbf{a}^T\\mathbf{P}\\mathbf{a}$$\n","\n","subject to:\n","\n","$$\n","\\begin{split}\n","0 \\leq a_i &\\leq \\frac{1}{N}, \\quad i=1,\\ldots,N \\\\\n","\\mathbf{y}^T \\mathbf{a} &= 0 \\\\\n","\\mathbb{1}_N^T\\mathbf{a} &\\geq \\nu\n","\\end{split}\n","$$"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c73a6a426a6b99f813340d022e71dd64","grade":false,"grade_id":"cell-14ec6862a8dccd45","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ZRo3d2llLh2D","colab_type":"code","colab":{}},"source":["np.random.seed(231)\n","n_samples = 100\n","data_sets_nu = []\n","\n","for i in range(2):\n","    # Generate random data\n","    X, y = make_blobs(100, centers=2, random_state=i+7, cluster_std=2.7)\n","    y[y == 0] = -1\n","    data_set = DataSet(*train_test_split(X, y, test_size=0.3))\n","    data_sets_nu.append(data_set)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c8f696e7e60b0586571d2b2bbc692ec0","grade":false,"grade_id":"cell-52de73c3b54a11df","locked":true,"schema_version":3,"solution":false,"task":false},"id":"HYrRT-_VLh2F","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(11,11))\n","gs = gridspec.GridSpec(2, 2)\n","gs.update(wspace=0.2, hspace=0.5)\n","\n","for i, data_set in enumerate(data_sets_nu):\n","    # Plot data\n","    ax = plt.subplot(gs[i])\n","    legend = 'upper left' if i == 0 else None\n","    plot_data(ax, data_set, legend)\n","    ax.text(0.5, -0.2, \"data set: {}\".format(i), size=12, ha=\"center\", transform=ax.transAxes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"287e4aa388d17e047b95751f042342db","grade":false,"grade_id":"cell-b0ba832213ce352e","locked":true,"schema_version":3,"solution":false,"task":false},"id":"UHRyQO5YLh2J","colab_type":"text"},"source":["### Task 3.1: Update the SVM Optimization to $\\nu$-SVM\n","Write the new constraints for the $\\nu$-SVM in the `optimize_nu_svm` function below."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"b2e3bb1a6ba94f686403a03815027065","grade":true,"grade_id":"cell-d8269cd85766d7f0","locked":false,"points":1,"schema_version":3,"solution":true,"task":false},"id":"SCWriqY1Lh2J","colab_type":"code","colab":{}},"source":["def optimize_nu_svm(X, y, nu, kernel=linear_kernel):\n","    \"\"\"\n","    \n","    :param X:      training values (type: numpy array of shape (N, n_features))\n","    :param y:      target values (type: numpy array of shape (N,))\n","    :param nu:     provides bounds on the support vectors, value has to be in interval (0, 1]\n","                   (type: float)\n","    :param kernel: kernel (type: function or callable object)\n","    :returns:      Lagrangian multipliers (type: numpy array of shape (N,))\n","                   None if optimization fails\n","    \"\"\"\n","    if nu <= 0 or nu > 1:\n","        raise ValueError(\"nu={} is invalid, value to be in interval (0, 1]\".format(nu))\n","    \n","    K = compute_gram_matrix(X, kernel)\n","    P = compute_P(K, y)\n","    P = 0.5 * (P + P.T) # make sure P is symmetric, increases stability of optimization\n","    \n","    N = y.shape[0]\n","    a = cp.Variable((N,1))\n","    L = cp.sum(a) - 0.5 * cp.quad_form(a, cp.Constant(P)) \n","    \n","    \"\"\"\n","    Write the appropriate constraints for the nu-SVM problem. \n","    \n","    Previous constraints were:\n","    \n","      constraints = [a >= 0, \n","                     a.T * y == 0]\n","    \"\"\"\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    objective = cp.Maximize(L)\n","    prob = cp.Problem(objective, constraints)\n","\n","    prob.solve()\n","    \n","    if a.value is None:\n","        print(\"No solution could be found, is the data linearly separable in the feature space?\")\n","        return None\n","    else:\n","        return a.value.reshape((-1,))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c9a292fa358bb8147206151996a6f550","grade":false,"grade_id":"cell-e82ce523296effd0","locked":true,"schema_version":3,"solution":false,"task":false},"id":"jvxCxcwgLh2M","colab_type":"code","colab":{}},"source":["class NuSVM(SVM):\n","    \"\"\"\n","    We can inherit almost all the functions from our original SVM class.\n","    Only the optmization function has changed.\n","    \"\"\"\n","    \n","    def __init__(self, nu, kernel):\n","        super(NuSVM, self).__init__(kernel)\n","        self.nu = nu\n","        \n","    def optmize(self, X, y):\n","        return optimize_nu_svm(X, y, self.nu, self.kernel)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"e20e8f8c1dec637cd1f2e300a22388a6","grade":false,"grade_id":"cell-087529439a0d46c4","locked":true,"schema_version":3,"solution":false,"task":false},"id":"qZZkKM_sLh2P","colab_type":"code","colab":{}},"source":["np.set_printoptions(precision=2)\n","plt.figure(figsize=(11,11))\n","gs = gridspec.GridSpec(2, 2)\n","gs.update(wspace=0.2, hspace=0.5)\n","\n","for i, data_set in enumerate(data_sets_nu):\n","    print(\"Solving for data set {}\".format(i))\n","    \n","    # Plot data\n","    ax = plt.subplot(gs[i])\n","    legend = 'upper left' if i == 0 else None\n","    plot_data(ax, data_set, legend)\n","        \n","    # Create SVM with linear kernel\n","    svm = NuSVM(nu=0.5, kernel=linear_kernel)\n","    \n","    # Fit the data\n","    success = svm.fit(data_set.X_train, data_set.y_train)\n","    if not success:\n","        break\n","    \n","    # Validate on test set  \n","    score = svm.score(data_set.X_test, data_set.y_test)\n","    \n","    # Plot margins and predictions\n","    svm.plot_decision_boundary(ax)\n","    \n","    pad_text = -0.2\n","    ax.text(0.5, pad_text, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.075, \"# support vectors: {}\".format(len(svm.svi)), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.15, \"w: {}\".format(svm.w), size=12, ha=\"center\", transform=ax.transAxes)\n","    ax.text(0.5, pad_text-0.225, \"b: {:.2}\".format(svm.b), size=12, ha=\"center\", transform=ax.transAxes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"5f62763514b001dbe06051fbbe464020","grade":false,"grade_id":"cell-4cea34314d0bc114","locked":true,"schema_version":3,"solution":false,"task":false},"id":"BzLYJL35Lh2R","colab_type":"text"},"source":["<a href=#objectives> [go to top] </a>\n","# Part 4: Multiclass SVM (Advanced) <a name='multiclass_svm' />\n","In the last part of this notebook we will be implementing a simple implementation to solve the multiclass SVM problem and evaluate on the iris data set. "]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"9c365ae57543895ba458339b38d0a956","grade":false,"grade_id":"cell-4c0eba042923f314","locked":true,"schema_version":3,"solution":false,"task":false},"id":"h-Dy64yOLh2R","colab_type":"code","colab":{}},"source":["from sklearn.datasets import load_iris\n","\n","iris_data_set = load_iris()\n","y = iris_data_set['target']\n","\n","# Select the 'RM' and 'LSTAT' columns from the dataset\n","used_features = ['sepal length (cm)', 'petal length (cm)']\n","data_col = list()\n","for col, val in enumerate(iris_data_set['feature_names']):\n","    if(val in used_features):\n","        data_col.append(col)\n","\n","X = iris_data_set['data'][:,data_col]\n","data_set_iris = DataSet(*train_test_split(X, y, test_size=0.3))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"0c973f7c2bfcdd52b1764ea6b3de7994","grade":false,"grade_id":"cell-00e06fb4ab19249d","locked":true,"schema_version":3,"solution":false,"task":false},"id":"rfHtawLnLh2T","colab_type":"code","colab":{}},"source":["def plot_iris_dataset(ax, data_set_iris, x_label = 'sepal length (cm)', y_label = 'sepal width (cm)'):\n","    X_train, X_test, y_train, y_test = data_set_iris\n","    \n","    # Scatter plotting the data, filtering them according the pos/neg values\n","    for i, label in enumerate(['setosa', 'versicolour', 'virginica']):\n","        idx_train = y_train == i\n","        idx_test = y_test == i\n","\n","        ax.scatter(X_train[idx_train, 0], X_train[idx_train, 1], s=30, c=[colors[i]], label='{} (train)'.format(label))\n","        ax.scatter(X_test[idx_test, 0], X_test[idx_test, 1], c=[colors[i]], s=50, marker='x', label='{} (test)'.format(label))\n","\n","    # Labels and limits\n","    ax.set_xlabel(x_label)\n","    ax.set_ylabel(y_label)\n","    ax.set_xlim(X[:, 0].min()-0.1, X[:, 0].max()+0.1)\n","    ax.set_ylim(X[:, 1].min()-0.1, X[:, 1].max()+0.1)\n","\n","    # Legend\n","    pst = ax.legend(loc='lower right', frameon=True)\n","    pst.get_frame().set_edgecolor('k')\n","    \n","\n","def plot_decision_boundary(ax, predict_function):        \n","    # plot the decision function\n","    xlim = ax.get_xlim()\n","    ylim = ax.get_ylim()\n","\n","    # create grid to evaluate model\n","    xx = np.linspace(xlim[0], xlim[1], 100)\n","    yy = np.linspace(ylim[0], ylim[1], 100)\n","    YY, XX = np.meshgrid(yy, xx)\n","    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n","\n","    Z = []\n","    for _x in xy:\n","        Z.append(predict_function(_x.reshape(1, -1)))\n","    Z = np.asarray(Z).reshape(XX.shape)\n","\n","    # plot decision boundary \n","    ax.contourf(XX, YY, Z, levels=2, colors=colors, alpha=0.1)\n","    ax.contour(XX, YY, Z, levels=2, colors=colors, alpha=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"cff747a791a17c53ea7d188111354267","grade":false,"grade_id":"cell-48a2b6e34978acd6","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ECXMOweyLh2V","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(7,5))\n","ax = plt.gca()\n","plot_iris_dataset(ax, data_set_iris)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"0295b754a3d433aa1f7f11b23b8b3b5c","grade":false,"grade_id":"cell-a32e2232f74f4feb","locked":true,"schema_version":3,"solution":false,"task":false},"id":"MUdSpvYBLh2Y","colab_type":"text"},"source":["### Task 4.1: Implement Multiclass SVM\n","One method for solve the multiclass SVM problem is the \"one versus the rest\" approach as explained in the lecture:\n","\n","1. Construct $M$ separate SVMs.\n","2. The $m$-th model $f_m(\\mathbf{x})$ is trained using data from class $C_m$ as positive examples ($y_m = +1$) and the data from the remaining $M - 1$ classes as negative samples $y_{i \\neq m} = -1$.\n","3. Train each model separately.\n","\n","For prediction return the class label associated with the model $m$ that returns a positive prediction ($+1$)."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"ef0ba5d57cf9093e82e5de15b83eeeda","grade":true,"grade_id":"cell-fc962353077ccca1","locked":false,"points":1,"schema_version":3,"solution":true,"task":false},"id":"MfXQIoxcLh2Y","colab_type":"code","colab":{}},"source":["class MulticlassSVM:\n","    \n","    def __init__(self, nu, kernel):\n","        self.nu = nu\n","        self.kernel = kernel\n","        \n","    def fit(self, X, y):\n","        \"\"\"\n","        Implement the training procedure for the Multiclass SVM.\n","        \n","        :param X: training values (type: numpy array of shape (N, n_features))\n","        :param y: target values (type: numpy array of shape (N,))\n","        :returns: True if successful, False otherwise (type: bool)\n","        \"\"\"\n","        \n","        # YOUR CODE HERE\n","        raise NotImplementedError()\n","        \n","        return True\n","        \n","    def predict(self, x):\n","        \"\"\"\n","        Implement the predictor for the Multiclass SVM.\n","        \n","        :param x: input sample (type: numpy array of shape (n_features,))\n","        :returns: predicted class (type: int)\n","        \"\"\"\n","        \n","        # YOUR CODE HERE\n","        raise NotImplementedError()\n","        \n","        return yhat\n","        \n","    def score(self, x, y):\n","        yhat = self.predict(x)\n","        return accuracy_score(y, yhat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"fbf5e40894af792a23ecc0f451f52a6d","grade":true,"grade_id":"cell-7740f8a5ef6a6dbe","locked":false,"points":1,"schema_version":3,"solution":true,"task":false},"id":"IrMEFHI2Lh2a","colab_type":"code","colab":{}},"source":["def return_multiclass_svm_iris(data_set_iris):\n","    \"\"\"\n","    Create a Multiclass SVM trained on the iris data set.\n","    \n","    Choose appropriate hyperpameter values and kernels. Play \n","    around and find some solution that solves the problem\n","    \n","    :param data_set_iris: the iris data set variable (type: DataSet)\n","    :returns:             trained MulticlassSVM (type: MulticlassSVM)\n","    \"\"\"\n","    X_train, _, y_train, _ = data_set_iris\n","    \n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    \n","    return svm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"f63bd7f8bcb18debc1295e8ae577c948","grade":false,"grade_id":"cell-8675d10ae3cb69b6","locked":true,"schema_version":3,"solution":false,"task":false},"id":"bcEyATRwLh2c","colab_type":"code","colab":{}},"source":["multiclass_svm = return_multiclass_svm_iris(data_set_iris)\n","score = multiclass_svm.score(data_set_iris.X_test, data_set_iris.y_test)\n","\n","plt.figure(figsize=(7,5))\n","ax = plt.gca()\n","plot_iris_dataset(ax, data_set_iris)\n","plot_decision_boundary(ax, multiclass_svm.predict)\n","_ = ax.text(0.5, -0.2, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"43867a4b859bd88e8be513bf7f5194b8","grade":false,"grade_id":"cell-aa6a452a011e458f","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ZaCDWGBPLh2e","colab_type":"text"},"source":["### Question 4: What is a Limitation of the \"One Versus All\" approach?\n","And can you come up with a modification to overcome this limitation?"]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"cell_type":"markdown","checksum":"12d2a8c300623a614706cfeb19f61b5e","grade":true,"grade_id":"cell-cc6a009bbc00ee4c","locked":false,"points":1,"schema_version":3,"solution":true,"task":false},"id":"o0ZJuhZ-Lh2f","colab_type":"text"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"5309d1934de62959b92d1cb2ebfa6ce9","grade":false,"grade_id":"cell-2c338a5ab880f347","locked":true,"schema_version":3,"solution":false,"task":false},"id":"TTf6UmofLh2f","colab_type":"text"},"source":["<a href=#objectives> [go to top] </a>\n","# Scikit-Learn Implementation <a name='sklearn' />"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c39aada94ce3aa9c83f6529ebd586d04","grade":false,"grade_id":"cell-5fff3d9667b3108f","locked":true,"schema_version":3,"solution":false,"task":false},"id":"ZvFRefhhLh2f","colab_type":"code","colab":{}},"source":["from sklearn.svm import SVC\n","# Scikit learn has a different default SVM implementation called C-Support Vector Classification\n","sk_svm = SVC(C=100000, kernel='poly', degree=2) \n","\n","sk_svm.fit(data_set_iris.X_train, data_set_iris.y_train)\n","score = sk_svm.score(data_set_iris.X_test, data_set_iris.y_test)\n","\n","plt.figure(figsize=(7,5))\n","ax = plt.gca()\n","plot_iris_dataset(ax, data_set_iris)\n","plot_decision_boundary(ax, sk_svm.predict)\n","_ = ax.text(0.5, -0.2, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)"],"execution_count":0,"outputs":[]}]}